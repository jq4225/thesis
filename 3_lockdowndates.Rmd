---
title: "3_lockdowndates"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(readxl)
library(lubridate)
```

```{r}
interventions_dirty <- 
read_excel('data/policy/Copy-of-Copy-of-Local-Policy-Responses-to-COVID-19.fin_ (1).xlsx',
           sheet = 'Local Policies') %>%
  # Get rid of city-specific policies
  filter(is.na(cityname)) %>%
  select(stfips, countyfips, stsipstart, stsipend, localsipstart, localsipend,
         dummysipstart, dummysipend, stbusclose, localbusclose, stbusopen, 
         localbusopen, dummybusclose, dummybusopen) %>%
  # Pick the earliest starts and the latest ends
  mutate(sipstart = ifelse(dummysipstart == 1, as_date(localsipstart), as_date(stsipstart)),
         sipend = ifelse(dummysipend == 1, as_date(localsipend), as_date(stsipend)),
         busclose = ifelse(dummybusclose == 1, as_date(localbusclose), as_date(stbusclose)),
         busopen = ifelse(dummybusopen == 1, as_date(localbusopen), as_date(stbusopen))) %>%
  select(stfips, countyfips, sipstart, sipend, busclose, busopen) %>%
  mutate(stfips = str_pad(stfips, width = 2, side = "left", pad = "0"),
         countyfips = str_pad(countyfips, width = 3, side = "left", pad = "0")) %>%
  mutate(fips = str_c(stfips, countyfips, sep = "")) %>%
  select(-stfips, -countyfips) %>%
  mutate(sipstart = as_date(sipstart),
         sipend = as_date(sipend),
         busclose = as_date(busclose),
         busopen = as_date(busopen)) %>%
  # Replace NAs with 2021 dates that never trigger to stop NA errors
  mutate(sipstart = replace_na(sipstart, as_date("2021-01-01")),
         sipend = replace_na(sipend, as_date("2021-01-01")),
         busclose = replace_na(busclose, as_date("2021-01-01")),
         busopen = replace_na(busopen, as_date("2021-01-01")))
```


```{r}
# Let's try to aggregate this by DMA and (maybe) week -- read in 
# goolsbee interventions

dma_codes <- read_csv('dma_codes.csv') %>%
  select(google_code, statefp, cntyfp) %>%
  mutate(statefp = str_pad(statefp, width = 2, side = "left", pad = "0"),
         cntyfp = str_pad(cntyfp, width = 3, side = "left", pad = 0)) %>%
  mutate(fips = str_c(statefp, cntyfp, sep = "")) %>%
  select(google_code, fips)

goolsbee_interventions <- readRDS('clean_data/goolsbee_interventions.rds') %>%
  mutate(across(c(`sipstart`:`busopen`), ~ ifelse(. == as_date("2021-01-01"),
                                                   as_date("2030-01-01"), .))) %>%
  mutate(across(c(`sipstart`:`busopen`), as_date))

# Unfinished

# Let's make a tibble of every FIPS-date combination

week_begin <- readRDS('week_begin.rds')

fips <- tibble(goolsbee_interventions$fips)

merged <- merge(week_begin, fips) %>%
  clean_names() %>%
  left_join(., goolsbee_interventions, by = c("goolsbee_interventions_fips" = "fips"))

# population data here

pop <- read_csv('data/county_stats/pop_race.csv', skip = 1) %>% 
  clean_names() %>%
  select(id, estimate_sex_and_age_total_population) %>%
  mutate(fips = str_sub(id, str_length(id) - 4, str_length(id))) %>%
  select(-id)

# This gives us a dataframe of all county implementation dates

merged2 <- merged %>%
  as_tibble() %>%
  mutate(date = as_date(date)) %>%
  mutate(sip = ifelse(sipstart <= (date + days(6)) & sipend >= date + days(6),
                      1, 0),
         busclose = ifelse(busclose <= (date + days(6)) & busopen >= date + days(6),
                           1, 0)) %>%
  select(date, goolsbee_interventions_fips, sip, busclose) %>%
  # merge in population data
  left_join(., pop, by = c("goolsbee_interventions_fips" = "fips")) %>%
  mutate(sip_pop = sip * estimate_sex_and_age_total_population,
         busclose_pop = busclose * estimate_sex_and_age_total_population)

# Now let's group this by DMA too -- read in the DMA codes here

merged3 <- left_join(merged2, dma_codes, by = c("goolsbee_interventions_fips" = "fips")) %>%
  drop_na(google_code) %>%
  group_by(date, google_code) %>%
  summarize(dmas = n(),
            sip_sum = sum(sip),
            busclose_sum = sum(busclose),
            pop = sum(estimate_sex_and_age_total_population),
            sip_pop = sum(sip_pop),
            busclose_pop = sum(busclose_pop)) %>%
  mutate(sip_prop = sip_sum / dmas,
         busclose_prop = busclose_sum / dmas,
         sip_first = ifelse(sip_sum > 0, 1, 0),
         busclose_first = ifelse(busclose_sum > 0, 1, 0),
         sip_pop_pct = sip_pop/pop,
         busclose_pop_pct = busclose_pop/pop) %>%
  mutate(sip_most_dma = ifelse(sip_prop >= 0.5, 1, 0),
         busclose_most_dma = ifelse(busclose_prop >= 0.5, 1, 0),
         sip_most_pop = ifelse(sip_pop_pct >= 0.5, 1, 0),
         busclose_most_pop = ifelse(busclose_pop_pct >= 0.5, 1, 0)) %>%
  select(date, google_code, sip_prop, busclose_prop,
         sip_first, busclose_first, sip_most_dma, busclose_most_dma,
         sip_pop_pct, busclose_pop_pct, sip_most_pop,
         busclose_most_pop)
```


```{r}
# now let's make a slight modification to our lockdowns indicator by making it
# for every year

dma_interventions <- readRDS('clean_data/dma_interventions.rds') %>%
  mutate(year = year(date)) %>%
  group_by(year, google_code) %>%
  mutate(week = 1:n()) %>%
  ungroup()

dma_interventions_20 <- dma_interventions %>%
  filter(year == 2020) %>%
  select(-date, -year)

# Note: version 2 just complies with our regression model estimation thing

dma_interventions_2 <- dma_interventions %>%
  select(date, google_code, year, week) %>%
  left_join(., dma_interventions_20, by = c("google_code", "week")) %>%
  group_by(google_code) %>%
  arrange(date) %>%
  fill(sip_prop:busclose_most_pop, .direction = "down")

week_begin <- readRDS('week_begin.rds') %>%
  as_tibble() %>%
  mutate(date = as_date(date))
```


```{r}
# State policy spreadsheets -- you need to add a state column to other things first

cgrt <- read_csv('data/policy/OxCGRT_latest.csv', col_types = cols()) %>%
  clean_names() %>%
  filter(country_code == "USA",
         jurisdiction == "STATE_TOTAL") %>%
  select(region_code, date, e1_income_support,
         e2_debt_contract_relief, economic_support_index) %>%
  # Based on previous AK data we replace the only missing values which are from
  # AK
  mutate(e1_income_support = replace_na(e1_income_support, 0),
         economic_support_index = replace_na(economic_support_index, 25)) %>%
  filter(date <= 20210105) %>%
  mutate(region_code = str_sub(region_code, start = 4),
         date = as.character(date)) %>%
  mutate(date = ymd(date))

# Let's do this weekly now 

week_begin <- readRDS('week_begin.rds') %>%
  mutate(date = as_date(date)) %>%
  # we want policy by the week's end
  mutate(week_end = date + days(6))

cgrt_weekly <- cgrt %>%
  filter(date %in% c(week_begin$week_end)) %>%
  mutate(date = date - days(6))
```


```{r}
# Join this onto searches v2 to make v3

searches_v3 <- readRDS('clean_data/search/searches_v2.rds') %>%
  left_join(., cgrt_weekly, by = c("state" = "region_code", "date")) %>%
  mutate(e1_income_support = replace_na(e1_income_support, 0),
         e2_debt_contract_relief = replace_na(e2_debt_contract_relief, 0),
         economic_support_index = replace_na(economic_support_index, 0)) %>%
  rename('income_support' = 'e1_income_support',
         'debt_contract_relief'= 'e2_debt_contract_relief') %>%
  mutate(year = as.factor(year),
         year_indicator = ifelse(year == "2020", 1, 0))

# Fixing searches v3 to have lagged covid cases instead of covid cases

searches_v3 <- readRDS('clean_data/search/searches_v3.rds') %>%
  group_by(dma) %>%
  arrange(date) %>%
  mutate(cases_per_100k = lag(cases_per_100k),
         deaths_per_100k = lag(deaths_per_100k)) %>%
  fill(c(`cases_per_100k`, `deaths_per_100k`), .direction = "up") %>%
  ungroup()

# to do: merge in lockdown dates and make some graphs
```

