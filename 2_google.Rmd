---
title: "2_google"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(gtrendsR)
library(readxl)
```

Search terms: (don't use anymore -- look at the google doc)

Depression: 640
Anxiety and Stress: 639
Mental Health: 437

Headaches & Migraines: 631
Sleep Disorders: 633

Movies: 34
Comics & Animation: 316
Books & Literature: 22
Music & Audio: 35
Online Media: 613
TV & Video: 36
Games: 8

Substance Abuse: 257
Subcats:
- Drug & Alcohol Treatment: 1350
- Smoking & Smoking Cessation: 1237

Alcoholic Beverages: 277
Tobacco Products: 123

```{r setup}
# Don't need to run this -- this is replication code from the junior paper, I
# have the results already

data(countries)

us_codes <- countries %>%
  filter(country_code == "US") %>%
  slice(20267:20476) %>%
  mutate(name = tolower(name)) %>%
  select(-country_code) %>%
  clean_names()

google_crosswalk <- read_csv('data/GoogleTrends_CountyDMA_Mapping.csv') %>%
  clean_names() %>%
  mutate(google_dma = tolower(google_dma))

dma_codes <- left_join(google_crosswalk, us_codes, by = c("google_dma" = "name"))

dma_codes_csv <- dma_codes %>%
  drop_na(sub_code) %>%
  mutate(state_dma = str_sub(google_dma, start = str_length(google_dma) - 1),
         dma_code = str_sub(sub_code, start = str_length(sub_code) - 2)) %>%
  mutate(google_code = str_c("US", state_dma, dma_code, sep = "-")) %>%
  mutate(google_code = toupper(google_code))
```

```{r}
# START HERE

dma_codes <- read_csv('dma_codes.csv', col_types = cols()) %>%
  select(google_code) %>%
  mutate(google_code = ifelse(google_code == "US-D)-511",
                              "US-DC-511", google_code)) %>%
  distinct()

dma_codes <- pull(dma_codes, google_code)

dma_codes <- sort(dma_codes)
```

```{r}
# And start reading in data here -- this is for individual search terms
search_term <- '/m/04rlf'

music <- tibble()

```


```{r}
# Run this

for(i in 1:54) {
  
  if(i < 53) {
    # Exception case for when we need to search twice for NY
    if(i != 32) {
       temp <- gtrends(keyword = search_term, geo = c('US-NY-501', dma_codes[(i-1)*4 + 1],
                                                 dma_codes[(i-1)*4 + 2],
                                                 dma_codes[(i-1)*4 + 3],
                                                 dma_codes[(i-1)*4 + 4]),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time
       
       temp <- temp %>% 
         # This is some shady rounding but only ever seems to matter for NY,
         # which we end up re-searching for anyway so it doesn't really matter
         mutate(hits = ifelse(hits == "<1", "0.5", hits)) %>%
         mutate(hits = as.numeric(hits)) %>%
         pivot_wider(id_cols = date, names_from = geo,
                                    values_from = hits) %>%
                        mutate_at(vars(3:6), ~ . * max(.)/max(`US-NY-501`))
    }
    else {
      temp <- gtrends(keyword = search_term, geo = c('US-NY-501', dma_codes[(i-1)*4 + 1],
                                                 dma_codes[(i-1)*4 + 2],
                                                 dma_codes[(i-1)*4 + 3],
                                                 dma_codes[(i-1)*4 + 4]),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time 
      
      temp <- temp %>% 
         # This is some shady rounding but only ever seems to matter for NY,
         # which we end up re-searching for anyway so it doesn't really matter
         mutate(hits = ifelse(hits == "<1", "0.5", hits)) %>%
         mutate(hits = as.numeric(hits)) %>%
        distinct() %>%
        pivot_wider(id_cols = date, names_from = geo,
                values_from = hits) %>%
        mutate_at(vars(3:5), ~ . * max(.)/max(`US-NY-501`))
    }
   
  }
  
  else if(i == 53) {
    temp <- gtrends(keyword = search_term, geo = c('US-NY-501', dma_codes[(i-1)*4 + 1]),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
      mutate(hits = ifelse(hits == "<1", "0.5", hits)) %>%
      mutate(hits = as.numeric(hits)) %>%
      pivot_wider(id_cols = date, names_from = geo,
                values_from = hits) %>%
      mutate_at(vars(3), ~ . * max(.)/max(`US-NY-501`))
  }
  
  else{
    temp <- gtrends(keyword = search_term, geo = c('US-NY-501'),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
      mutate(hits = ifelse(hits == "<1", "0.5", hits)) %>%
      mutate(hits = as.numeric(hits)) %>%
      pivot_wider(id_cols = date, names_from = geo,
                  values_from = hits) %>%
      rename(`US-NY-501-FINAL` = `US-NY-501`)
  }
  
  if(i == 1) {
    music <- temp
  }
  else {
    music <- cbind(music, temp)

  }
  Sys.sleep(3)
  
  print(i)
}

music_clean <- music[, -which(duplicated(names(music)))] %>%
  select(-`US-NY-501`) %>%
  rename(`US-NY-501` = `US-NY-501-FINAL`)

music_clean_2 <- music_clean %>%
  pivot_longer(cols = `US-AK-743`:`US-NY-501`, names_to = "dma", 
               values_to = "music")

saveRDS(music_clean_2, file = "music_scaled.rds")
```

```{r}
# Getting the week beginning dates -- each date is the BEGINNING of the week

week_begin <- sadness_clean %>%
  select(date)

```

```{r}
# And this is for categories

category <- '639'

depression <- tibble()
```


```{r}
# Run this

for(i in 1:54) {
  
  if(i < 53) {
    temp <- gtrends(cat = category, geo = c('US-NY-501', dma_codes[(i-1)*4 + 1],
                                                 dma_codes[(i-1)*4 + 2],
                                                 dma_codes[(i-1)*4 + 3],
                                                 dma_codes[(i-1)*4 + 4]),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
    pivot_wider(id_cols = date, names_from = geo,
                values_from = hits) %>%
    mutate_at(vars(3:6), ~ . * max(.)/max(`US-NY-501`))
  }
  
  else if(i == 53) {
    temp <- gtrends(cat = category, geo = c('US-NY-501', dma_codes[(i-1)*4 + 1]),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
    pivot_wider(id_cols = date, names_from = geo,
                values_from = hits) %>%
    mutate_at(vars(3), ~ . * max(.)/max(`US-NY-501`))
  }
  
  else{
    temp <- gtrends(cat = category, geo = c('US-NY-501'),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
      pivot_wider(id_cols = date, names_from = geo,
                  values_from = hits) %>%
      rename(`US-NY-501-FINAL` = `US-NY-501`)
  }
  
  if(i == 1) {
    depression <- temp
  }
  else {
    depression <- cbind(depression, temp)
  }
  Sys.sleep(3)
  
  print(i)
}

depression_clean <- depression[, -which(duplicated(names(depression)))] %>%
  select(-`US-NY-501`) %>%
  rename(`US-NY-501` = `US-NY-501-FINAL`)

saveRDS(depression_clean, file = "depression_scaled.rds")
```
```{r}
# For only one DMA at a time ... 

for(i in 1:209) {
  temp <- gtrends(cat = category, geo = dma_codes[i],
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time %>%
                pivot_wider(id_cols = date, names_from = geo,
                values_from = hits)
  
  if(i == 1) {
    depression <- temp
  }
  else {
    temp <- temp %>%
        select(-date)
    
    depression <- cbind(depression, temp)
  }
  Sys.sleep(3)
  
  print(i)
}

# depression_clean <- depression[, -which(duplicated(names(depression)))] %>%
#   select(-`US-NY-501`) %>%
#   rename(`US-NY-501` = `US-NY-501-FINAL`)
```

```{r}
# Internet user data by DMA

dma_codes <- read_csv('dma_codes.csv') %>%
  select(google_code, statefp, cntyfp) %>%
  mutate(statefp = str_pad(statefp, width = 2, side = "left", pad = "0"),
         cntyfp = str_pad(cntyfp, width = 3, side = "left", pad = 0)) %>%
  mutate(fips = str_c(statefp, cntyfp, sep = "")) %>%
  select(google_code, fips)

# internet <- read_excel("data/county_stats/county_connections_dec_2018.xlsx",
#                        sheet = "County Connections Dec 2018") %>%
#   mutate_at(c("consumer", "non_consumer", "all", "ratio"),
#             ~ ifelse(. == -9999, 0, .))

internet <- read_excel("data/county_stats/broadband_long2000-2018rev.xlsx") %>%
  filter(year == 2018) %>%
  select(id, broadband, cfips) %>%
  mutate(cfips = str_pad(cfips, width = 5, side = "left", pad = "0"))

# match with population

population <- read_csv("data/county_stats/pop_race.csv", skip = 1) %>%
  clean_names() %>%
  select(id, estimate_sex_and_age_total_population, 
         estimate_sex_and_age_total_population_5_to_9_years,
         estimate_sex_and_age_total_population_5_to_9_years,
         estimate_sex_and_age_total_population_10_to_14_years) %>%
  mutate(adult_pop = estimate_sex_and_age_total_population - 
           estimate_sex_and_age_total_population_5_to_9_years - 
           estimate_sex_and_age_total_population_10_to_14_years) %>%
  select(id, adult_pop)

internet_users <- left_join(internet, population, by = "id") %>%
  drop_na(adult_pop) %>%
  mutate(internet_users = broadband * adult_pop / 1000) %>%
  select(cfips, internet_users)

# Match with DMA

dma_internet <- left_join(internet_users, dma_codes, by = c("cfips" = "fips")) %>%
  drop_na(google_code) %>%
  select(-cfips) %>%
  group_by(google_code) %>%
  summarize(internet_users = sum(internet_users))
```


```{r}
# Some sample plots

crying_clean %>%
  mutate(mean = rowMeans(across(where(is.numeric)))) %>%
  ggplot(mapping = aes(x = date, y = mean)) +
    geom_line()
```

```{r}
# TESTING 

word <- gtrends(keyword = 'anxiety', geo = c('US-NY-501', 'US-AL-606'),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time

topic <- gtrends(keyword = '/m/05c7vv', geo = c('US-NY-501'),
                            time = '2016-01-01 2020-12-31', 
                         onlyInterest = TRUE)$interest_over_time
```


```{r}
# Longing the data that wasn't long before 

depression_clean <- readRDS('clean_data/search/depression_scaled.rds')

depression_clean_2 <- depression_clean %>%
  pivot_longer(cols = `US-AK-743`:`US-NY-501`, names_to = "dma", 
               values_to = "depression")

saveRDS(depression_clean_2, file = "depression_scaled.rds")

# Editing some of the stuff we're doing that had bad results

depression_scaled <- readRDS('clean_data/search/long/depression_scaled.rds') %>%
  select(date, dma, depression) %>%
  mutate(dma = str_replace(dma, ".x", ""))

saveRDS(depression_scaled, file = "depression_scaled.rds")
```


```{r}
# Let's combine our data together!

searches <- tibble()

files <- list.files(path = 'clean_data/search/long')

for(i in 1:length(files)) {
  temp <- readRDS(paste('clean_data/search/long/', files[i], sep = ""))
  
  if(i == 1) {
    searches <- temp
  }
  else {
    searches <- left_join(searches, temp, by = c("dma", "date"))
  }
}
```


```{r}

# Let's combine some of the time series stuff we have 

# Read in unemployment

dma_unemploy <- readRDS('clean_data/dma_unemploy.rds') %>%
  mutate(year = as.numeric(year),
         period = as.numeric(period))

# Read in covid

dma_covid <- readRDS('clean_data/covid_dma.rds')

# Bring in searches

searches_2 <- searches %>%
  mutate(month = month(date), year = year(date)) %>%
  left_join(., dma_unemploy, by = c("year", "month" = "period", 
                                    "dma" = "google_code")) %>%
  select(-unemploy, -labor_force)

# Bring in COVID -- this is searches v2

searches_3 <- searches_2 %>%
  mutate(date = as_date(date)) %>%
  left_join(., dma_covid, by = c("dma" = "google_code",
                                  "date")) %>%
  select(-total_pop) %>%
  mutate(cases_per_100k = replace_na(cases_per_100k, 0),
         deaths_per_100k = replace_na(cases_per_100k, 0))

# Modify searches v2 quickly to have state indicators

searches_v2 <- searches_v2 %>%
  mutate(state = str_sub(dma, start = 4, end = 5))


```

